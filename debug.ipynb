{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abca1475-766c-4eba-9c69-2a11a4ffdc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from args import *\n",
    "from utils import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b38a33-a7f7-4f93-a620-3e5fba7b0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.dataset = 'phone-email'\n",
    "        self.ratio = 0.2\n",
    "        self.use_attr = False\n",
    "        self.device = 'cpu'\n",
    "        self.model = 'BRIGHT'\n",
    "        self.num_layers = 1\n",
    "        self.hidden_dim = 128\n",
    "        self.out_dim = 128\n",
    "        self.lambda_w = 1\n",
    "        self.lambda_edge = 0\n",
    "        self.lambda_total = 1e-2\n",
    "        self.in_iter = 5\n",
    "        self.out_iter = 10\n",
    "        self.lr = 1e-3\n",
    "        self.epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afcf532f-3843-448b-9738-8cfe3435cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... Done\n",
      "Loading RWR scores from datasets/rwr/rwr_emb_phone-email_0.2.npz... Done\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "# check compatibility between dataset and use_attr\n",
    "if args.dataset == 'noisy-cora1-cora2':\n",
    "    assert args.use_attr is True, 'noisy-cora1-cora2 requires using node attributes'\n",
    "elif args.dataset == 'foursquare-twitter' or args.dataset == 'phone-email':\n",
    "    assert args.use_attr is False, f'{args.dataset} does not have node attributes'\n",
    "\n",
    "# load data and build networkx graphs\n",
    "np_dtype = np.float64\n",
    "torch_dtype = torch.float64\n",
    "print(\"Loading data...\", end=\" \")\n",
    "edge_index1, edge_index2, x1, x2, anchor_links, test_pairs = load_data(f\"datasets/{args.dataset}\", args.ratio,\n",
    "                                                                       args.use_attr, dtype=np_dtype)\n",
    "anchor1, anchor2 = anchor_links[:, 0], anchor_links[:, 1]\n",
    "G1, G2 = build_nx_graph(edge_index1, anchor1, x1), build_nx_graph(edge_index2, anchor2, x2)\n",
    "print(\"Done\")\n",
    "\n",
    "rwr1, rwr2 = get_rwr_matrix(G1, G2, anchor_links, args.dataset, args.ratio, dtype=np_dtype)\n",
    "if x1 is None:\n",
    "    x1 = rwr1\n",
    "if x2 is None:\n",
    "    x2 = rwr2\n",
    "\n",
    "# device setting\n",
    "assert torch.cuda.is_available() or args.device == 'cpu', 'CUDA is not available'\n",
    "device = torch.device(args.device)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# build PyG Data objects\n",
    "G1_tg = build_tg_graph(edge_index1, x1, rwr1, dtype=torch_dtype).to(device)\n",
    "G2_tg = build_tg_graph(edge_index2, x2, rwr2, dtype=torch_dtype).to(device)\n",
    "\n",
    "# model setting\n",
    "input_dim = G1_tg.x.shape[1]\n",
    "hidden_dim = args.hidden_dim\n",
    "output_dim = args.out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26660c46-53ce-4e23-8646-97c947ef5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BRIGHT(input_dim=input_dim, hidden_dim=output_dim, output_dim=output_dim).to(device)\n",
    "if args.model == 'PGNA':\n",
    "    model = PGNA(input_dim=input_dim,\n",
    "                 feature_dim=output_dim,\n",
    "                 anchor_dim=anchor_links.shape[0],\n",
    "                 hidden_dim=output_dim,\n",
    "                 output_dim=output_dim,\n",
    "                 num_layers=args.num_layers).to(device)\n",
    "elif args.model == 'RWRNet':\n",
    "    model = RWRNet(num_layers=args.num_layers,\n",
    "                   input_dim=input_dim,\n",
    "                   output_dim=output_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion = FusedGWLoss(G1_tg, G2_tg, anchor1, anchor2,\n",
    "                        lambda_w=args.lambda_w,\n",
    "                        lambda_edge=args.lambda_edge,\n",
    "                        lambda_total=args.lambda_total,\n",
    "                        in_iter=args.in_iter,\n",
    "                        out_iter=args.out_iter).to(device)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f357ddcc-a378-4fb2-9318-9cba5806e781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0, 631, 888,  ..., 854, 212,  99],\n",
      "        [  1, 705, 162,  ..., 854,  99,   0],\n",
      "        [296, 877, 718,  ..., 669, 396, 854],\n",
      "        ...,\n",
      "        [997, 682, 550,  ..., 575, 854, 340],\n",
      "        [296, 877, 718,  ..., 396, 854,   0],\n",
      "        [503, 999,  17,  ...,   0, 396, 854]])\n",
      "tensor([[  0,   1, 529,  ..., 889, 889, 889],\n",
      "        [383, 970, 408,  ..., 555, 555, 555],\n",
      "        [290, 155, 998,  ..., 206, 206, 206],\n",
      "        ...,\n",
      "        [ 99, 898, 471,  ..., 863, 863, 863],\n",
      "        [952, 952,   0,  ..., 898, 898, 898],\n",
      "        [589,   0, 898,  ...,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "r1 = G1_tg.rwr / torch.linalg.norm(G1_tg.rwr, ord=2, dim=1, keepdim=True)\n",
    "r2 = G2_tg.rwr / torch.linalg.norm(G2_tg.rwr, ord=2, dim=1, keepdim=True)\n",
    "crossC = torch.exp(-r1 @ r2.T)\n",
    "rank_cross_row = torch.argsort(crossC, dim=1)\n",
    "rank_cross_col = torch.argsort(crossC, dim=0)\n",
    "print(rank_cross_row)\n",
    "print(rank_cross_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a0a0ed2-3846-49f1-96e8-50ea5fce9470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3882)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossC[2, 296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e5b1beff-597b-468c-962a-7263e8899359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([770, 296, 432, 264, 551, 511, 365, 657, 868, 690, 614, 830, 701, 184,\n",
       "        363, 160, 904, 531, 265, 877, 998,  53, 334, 875, 719, 441, 292, 408,\n",
       "        438, 765, 321, 588, 594, 718, 476, 306, 404, 391, 293, 454, 843, 498,\n",
       "        165, 981, 101, 895, 798, 529, 364, 344, 458, 776, 564, 505, 274, 163,\n",
       "        254, 672, 161, 145, 126, 235, 837, 647, 516, 452, 945, 766,   2, 959,\n",
       "        947, 103, 418, 297, 587, 357, 788, 372, 991, 302, 668, 106, 942, 862,\n",
       "        420, 562, 156, 827, 320, 202, 799, 939, 601, 650, 567, 805, 999,  88,\n",
       "         26, 737])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_cross_col[:100, 296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "645c678a-4923-4885-a2a0-1352d0a8694c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3785)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossC[296, 296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f82951d0-8948-4f9c-ae5d-c5fb853bc4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: -0.370018, cost_entropy: 13.818481, s_entropy: 13.818087, Hits@1: 0.0000, Hits@5: 0.0025, Hits@10: 0.0138, Hits@30: 0.1875, Hits@50: 0.4437, Hits@100: 0.8525, MRR: 0.0231\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "start = time.time()\n",
    "optimizer.zero_grad()\n",
    "out1, out2 = model(G1_tg, G2_tg)\n",
    "loss = criterion(out1=out1, out2=out2)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(f'Epoch {epoch + 1}, Loss: {loss.item():.6f}', end=', ')\n",
    "\n",
    "# testing\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inter_c = torch.exp(-(out1 @ out2.T))\n",
    "    intra_c1, intra_c2 = criterion.intra_c1, criterion.intra_c2\n",
    "    similarity = sinkhorn(inter_c, intra_c1, intra_c2,\n",
    "                          lambda_w=args.lambda_w,\n",
    "                          lambda_e=args.lambda_edge,\n",
    "                          lambda_t=args.lambda_total,\n",
    "                          in_iter=args.in_iter,\n",
    "                          out_iter=args.out_iter,\n",
    "                          device=device)\n",
    "    hits, mrr = compute_metrics(-similarity, test_pairs)\n",
    "    cost = inter_c / inter_c.sum()\n",
    "    cost_entropy = torch.sum(-cost * torch.log(cost))\n",
    "    s_entropy = torch.sum(-similarity * torch.log(similarity))\n",
    "    end = time.time()\n",
    "    print(f'cost_entropy: {cost_entropy:.6f}, s_entropy: {s_entropy:.6f}, '\n",
    "          f'{\", \".join([f\"Hits@{key}: {value:.4f}\" for (key, value) in hits.items()])}, MRR: {mrr:.4f}')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82e4bc73-bc36-44f2-9f1d-badd633ba0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3679003101137131\n",
      "0.3678794411714423\n",
      "tensor([[  0, 631, 860, 102, 890],\n",
      "        [  1, 215, 742,  60, 720],\n",
      "        [317, 267, 568, 141, 818],\n",
      "        [581,  40, 107,  89,  14],\n",
      "        [  4, 606, 215, 925,   1],\n",
      "        [852, 203, 439, 283, 992],\n",
      "        [203, 852, 439, 992, 283],\n",
      "        [603, 758, 902,  47, 761],\n",
      "        [  8, 980, 852, 760, 150],\n",
      "        [876, 845,  83, 416, 574]])\n",
      "(tensor([1]),) (tensor([803]),)\n",
      "(tensor([910]),) (tensor([842]),)\n",
      "(tensor([983]),) (tensor([916]),)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(f'{inter_c[0, 0]:.16f}')\n",
    "    print(f'{1/torch.exp(torch.tensor(1)):.16f}')\n",
    "    rank_c_row = torch.argsort(inter_c, dim=1)\n",
    "    rank_c_col = torch.argsort(inter_c, dim=0)\n",
    "    rank = torch.argsort(-similarity, dim=1)\n",
    "    print(rank[:10, :5])\n",
    "    print(torch.where(rank_c_row[0, :] == rank[0, 1]), torch.where(rank_c_row[0, :] == rank[0, 2]))\n",
    "    print(torch.where(rank_c_row[2, :] == rank[2, 0]), torch.where(rank_c_row[2, :] == rank[2, 1]))\n",
    "    print(torch.where(rank_c_row[3, :] == rank[3, 0]), torch.where(rank_c_row[3, :] == rank[3, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91eb17ed-75f3-4a8b-b3ba-b94076ab02cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist: 0.00000000000000000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Sinkhorn\n",
    "nx, ny = 50, 50\n",
    "crossC = torch.ones(nx, ny).to(torch.float64)\n",
    "crossC[torch.randperm(nx), torch.randperm(ny)] = 0\n",
    "intraC1 = torch.rand(nx, ny).to(torch.float64)\n",
    "intraC2 = torch.rand(nx, ny).to(torch.float64)\n",
    "S = sinkhorn(crossC, intraC1, intraC2, lambda_w=1, lambda_e=0, lambda_t=1e-2, in_iter=10, out_iter=100)\n",
    "plt.imshow(S, cmap='gray')\n",
    "print('Dist: %.20f' % torch.sum(crossC * S)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0039196e-4290-40de-8be2-256952370271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0447, dtype=torch.float64)\n",
      "tensor([[0.0447]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "nx, ny = 50, 30\n",
    "eps = 1e-5\n",
    "a = torch.ones(nx).to(torch.float64) / nx\n",
    "b = torch.ones(ny).to(torch.float64) / ny\n",
    "cost = torch.rand(nx, ny).to(torch.float64)\n",
    "f = torch.ones(nx).to(torch.float64) / nx\n",
    "g = torch.ones(ny).to(torch.float64) / ny\n",
    "\n",
    "def soft_min_row(z_in, eps):\n",
    "    hard_min = torch.min(z_in, dim=1, keepdim=True)[0]\n",
    "    soft_min = hard_min - eps * torch.log(torch.sum(torch.exp(-(z_in - hard_min) / eps), dim=1, keepdim=True))\n",
    "    return soft_min.squeeze(-1)\n",
    "\n",
    "def soft_min_col(z_in, eps):\n",
    "    hard_min = torch.min(z_in, dim=0, keepdim=True)[0]\n",
    "    soft_min = hard_min - eps * torch.log(torch.sum(torch.exp(-(z_in - hard_min) / eps), dim=0, keepdim=True))\n",
    "    return soft_min.squeeze(0)\n",
    "\n",
    "for i in range(100000):\n",
    "    f = soft_min_row(cost - g.view(1, -1), eps) + eps * torch.log(a)\n",
    "    g = soft_min_col(cost - f.view(-1, 1), eps) + eps * torch.log(b)\n",
    "    \n",
    "S = torch.exp((f.view(-1, 1) + g.view(-1, 1).T - cost) / eps)\n",
    "S += 1e-20\n",
    "print(torch.sum(cost * S) + eps * torch.sum(S * (torch.log(S) - 1)) + eps)\n",
    "print(eps * (a.view(1, -1) @ (f/eps).view(-1, 1) + b.view(1, -1) @ (g/eps).view(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5098beaa-b365-4da6-9590-d118c2f6892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(S.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6fd93ae6-aef6-4d30-8cb9-2d5a8a679ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "for i in range(100000):\n",
    "    av = torch.rand(n)\n",
    "    bv = torch.rand(n)\n",
    "    av /= -torch.linalg.norm(av, ord=2)\n",
    "    bv /= -torch.linalg.norm(bv, ord=2)\n",
    "    s = torch.sum(av * bv)\n",
    "    if s < -1 or s > 1:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6eaaba3a-daa6-4961-9cb9-156758cb8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2 = 1000, 1200\n",
    "a = torch.rand(n1).to(torch.float64)\n",
    "a = a / a.sum()\n",
    "b = torch.rand(n2).to(torch.float64)\n",
    "b = b / b.sum()\n",
    "C = torch.rand(n1, n2).to(torch.float64)\n",
    "eps = 1e-4\n",
    "global_delta = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bfb93d-41fa-40c6-914d-46c53a058745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "u = torch.ones(n1).to(torch.float64) / n1\n",
    "v = torch.ones(n2).to(torch.float64) / n2\n",
    "K = torch.exp(-C / eps)\n",
    "\n",
    "start_time = time.time()\n",
    "n_iter = 0\n",
    "while True:\n",
    "    u = a / (K @ v)\n",
    "    v = b / (K.T @ u)\n",
    "    S = torch.diag(u) @ K @ torch.diag(v)\n",
    "    err1 = torch.sum(torch.abs(torch.sum(S, dim=1) - a))\n",
    "    err2 = torch.sum(torch.abs(torch.sum(S, dim=0) - b))\n",
    "    err = err1 + err2\n",
    "    if err < global_delta:\n",
    "        break\n",
    "    if n_iter % 100 == 99:\n",
    "        print(f'iter: {n_iter + 1}, err: {err:.15f}')\n",
    "    n_iter += 1\n",
    "end_time = time.time()\n",
    "S_ground = torch.clone(S)\n",
    "print(f'Time: {end_time - start_time:.4f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0496a44-7c9a-4364-9f4d-2fa5dff18aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOT\n",
    "r = 500\n",
    "alpha = 1e-5\n",
    "gamma = 100\n",
    "delta = 1e-10\n",
    "\n",
    "Q = torch.ones(n1, r).to(torch.float64) / (n1 * r)\n",
    "R = torch.ones(n2, r).to(torch.float64) / (n2 * r)\n",
    "g = torch.ones(r).to(torch.float64) / r\n",
    "\n",
    "\n",
    "def LR_Dykstra(Ks, a, b, alpha, max_iter=1000, delta=1e-9, lam=0):\n",
    "    K1, K2, K3 = Ks\n",
    "    Q = K1\n",
    "    R = K2\n",
    "    g_old = K3\n",
    "\n",
    "    n1, n2 = K1.shape[0], K2.shape[0]\n",
    "    r = K3.shape[0]\n",
    "    \n",
    "    v1_old = torch.ones(r).to(torch.float64)\n",
    "    v2_old = torch.ones(r).to(torch.float64)\n",
    "    u1 = torch.ones(n1).to(torch.float64)\n",
    "    u2 = torch.ones(n2).to(torch.float64)\n",
    "\n",
    "    q_gi = torch.ones(r).to(torch.float64)\n",
    "    q_gp = torch.ones(r).to(torch.float64)\n",
    "    q_Q = torch.ones(r).to(torch.float64)\n",
    "    q_R = torch.ones(r).to(torch.float64)\n",
    "\n",
    "    err = 1\n",
    "    n_iter = 0\n",
    "    while n_iter < max_iter:\n",
    "        u1_prev, v1_prev = u1, v1_old\n",
    "        u2_prev, v2_prev = u2, v2_old\n",
    "        g_prev = g_old\n",
    "        if err > delta:\n",
    "            n_iter += 1\n",
    "\n",
    "            # First Projection\n",
    "            u1 = a / (K1 @ v1_old + lam)\n",
    "            u2 = b / (K2 @ v2_old + lam)\n",
    "            g = torch.max(torch.tensor(alpha), g_old * q_gi)\n",
    "            q_gi = (g_old * q_gi) / (g + lam)\n",
    "            g_old = torch.clone(g)\n",
    "\n",
    "            # Second Projection\n",
    "            v1_trans = K1.T @ u1\n",
    "            v2_trans = K2.T @ u2\n",
    "            g = (g_old * q_gp * v1_old * q_Q * v1_trans * v2_old * q_R * v2_trans) ** (1 / 3)\n",
    "            v1 = g / (v1_trans + lam)\n",
    "            v2 = g / (v2_trans + lam)\n",
    "            q_gp = (g_old * q_gp) / (g + lam)\n",
    "            q_Q = (q_Q * v1_old) / (v1 + lam)\n",
    "            q_R = (q_R * v2_old) / (v2 + lam)\n",
    "\n",
    "            v1_old = torch.clone(v1)\n",
    "            v2_old = torch.clone(v2)\n",
    "            g_old = torch.clone(g)\n",
    "\n",
    "            # Update the error\n",
    "            u1_trans = K1 @ v1\n",
    "            err_1 = torch.sum(torch.abs(u1 * u1_trans - a))\n",
    "            u2_trans = K2 @ v2\n",
    "            err_2 = torch.sum(torch.abs(u2 * u2_trans - b))\n",
    "            err = err_1 + err_2\n",
    "\n",
    "            if (\n",
    "                torch.any(torch.isnan(u1)) or\n",
    "                torch.any(torch.isnan(u2)) or\n",
    "                torch.any(torch.isnan(v1)) or\n",
    "                torch.any(torch.isnan(v2)) or\n",
    "                torch.any(torch.isinf(u1)) or\n",
    "                torch.any(torch.isinf(u2)) or\n",
    "                torch.any(torch.isinf(v1)) or\n",
    "                torch.any(torch.isinf(v2))\n",
    "            ):\n",
    "                print(f\"Warning: numerical error in Dyskra at iteration {n_iter}\")\n",
    "                u1, v1 = u1_prev, v1_prev\n",
    "                u2, v2 = u2_prev, v2_prev\n",
    "                g = g_prev\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            Q = u1.view(-1, 1) * K1 * v1.view(1, -1)\n",
    "            R = u2.view(-1, 1) * K2 * v2.view(1, -1)\n",
    "            return Q, R, g, n_iter\n",
    "\n",
    "    Q = u1.view(-1, 1) * K1 * v1.view(1, -1)\n",
    "    R = u2.view(-1, 1) * K2 * v2.view(1, -1)\n",
    "    return Q, R, g, n_iter\n",
    "\n",
    "epochs = 0\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    xi1 = torch.exp(-gamma * C @ R @ torch.diag(1/g) - (gamma * eps - 1) * torch.log(Q))\n",
    "    xi2 = torch.exp(-gamma * C.T @ Q @ torch.diag(1/g) - (gamma * eps - 1) * torch.log(R))\n",
    "    omega = torch.diagonal(Q.T @ C @ R)\n",
    "    xi3 = torch.exp(gamma * omega / (g ** 2) - (gamma * eps - 1) * torch.log(g))\n",
    "    Q, R, g, n_iter = LR_Dykstra((xi1, xi2, xi3), a, b, alpha, delta=delta)\n",
    "    S = Q @ torch.diag(1 / g) @ R.T\n",
    "    err = torch.sum(torch.abs(S - S_ground))\n",
    "    if err < global_delta:\n",
    "        break\n",
    "    if epochs % 100 == 99:\n",
    "        print(f'iter: {epochs + 1}, err: {err:.15f}')\n",
    "    epochs += 1\n",
    "    \n",
    "end_time = time.time()\n",
    "print(f'Time: {end_time - start_time:.4f}s')\n",
    "print(S.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
